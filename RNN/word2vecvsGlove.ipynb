{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec vs GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchnlp.word_to_vector import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0871, -2.0126,  1.0752, -1.3317, -0.3909],\n",
      "        [-0.2993, -0.6766,  1.6747, -0.6212,  0.6917]], requires_grad=True)\n",
      "Embedding(2, 5)\n",
      "tensor([[-0.2993, -0.6766,  1.6747, -0.6212,  0.6917]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "tensor([[ 0.0871, -2.0126,  1.0752, -1.3317, -0.3909],\n",
      "        [-0.2993, -0.6766,  1.6747, -0.6212,  0.6917]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "word_to_ix={\"hello\":0, \"world\":1}\n",
    "\n",
    "lookup_tensor=torch.tensor([word_to_ix[\"world\"]], dtype=torch.long)\n",
    "print(lookup_tensor)\n",
    "\n",
    "embeds=nn.Embedding(2, 5)\n",
    "for p in embeds.parameters():\n",
    "    print(p)\n",
    "print(embeds)\n",
    "world_embed=embeds(lookup_tensor)\n",
    "print(world_embed)\n",
    "lookup_tensor=torch.tensor([0,1], dtype=torch.long)\n",
    "world_embed=embeds(lookup_tensor)\n",
    "print(world_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.3893e-01, -1.9056e-02, -3.3891e-01,  1.2151e-01,  3.6523e-01,\n",
      "        -1.7391e-01, -2.6735e-02, -5.0335e-02,  2.4743e-01,  2.4531e+00,\n",
      "        -4.2113e-01,  2.3632e-01,  2.0513e-01, -1.0937e-02, -1.1480e-01,\n",
      "        -3.7648e-02, -1.3440e-01,  8.6124e-01, -3.5803e-01,  9.2525e-02,\n",
      "         2.8075e-01,  1.3649e-01,  2.0819e-01,  6.0206e-02, -1.8229e-01,\n",
      "         1.0172e-01, -1.3200e-01, -3.1598e-01,  2.2241e-01, -1.9076e-01,\n",
      "        -1.0884e-02,  1.6988e-01,  8.0345e-03,  1.3337e-01,  1.7724e-01,\n",
      "        -1.9162e-01,  3.3681e-01,  3.0186e-01,  6.1654e-02,  7.6906e-03,\n",
      "        -5.4406e-01,  5.0142e-02, -4.3115e-02, -2.6241e-01,  4.7462e-02,\n",
      "         3.3670e-01, -2.8649e-01, -2.7414e-01,  2.6776e-02, -6.5939e-02,\n",
      "         1.1021e-01,  2.8869e-01,  4.6712e-01,  1.2063e-01,  3.3831e-01,\n",
      "        -3.0427e-04, -1.2116e-01, -1.5900e-01, -1.0514e-01, -3.8560e-02,\n",
      "        -6.2205e-02,  3.5631e-02, -1.7852e-01, -1.3308e-01,  2.6103e-01,\n",
      "        -1.1082e-01, -2.7463e-01,  1.8556e-01,  4.5257e-01,  3.0336e-01,\n",
      "         6.1801e-02,  7.7310e-02,  3.4645e-01,  3.6526e-03,  4.6815e-01,\n",
      "         2.0228e-02, -2.5509e-02, -1.9465e-02, -5.3998e-03,  8.6497e-02,\n",
      "        -5.3099e-02, -8.6426e-02, -4.6913e-01,  6.5788e-02, -1.2720e-01,\n",
      "        -2.4254e-01,  2.4149e-01, -3.7684e-01,  6.5707e-01,  1.4106e-01,\n",
      "        -2.1080e-01,  1.1095e-01,  1.2741e-01, -2.8938e-01, -7.5295e-02,\n",
      "         4.4109e-02,  5.4280e-02, -2.9666e-01,  1.6423e-02,  4.4086e-02,\n",
      "         7.2862e-02, -3.0149e-01,  3.4613e-02,  8.6731e-02,  3.1091e-01,\n",
      "        -3.7156e-01,  1.7382e-01,  2.1996e-01,  6.0312e-02,  1.6767e-01,\n",
      "         3.8469e-02, -6.3231e-01,  3.2331e-01,  1.0421e-01,  2.5080e-01,\n",
      "         2.6267e-01,  1.7882e-01, -2.4515e-01, -1.7214e-01,  2.8319e-01,\n",
      "         6.5598e-02, -4.4386e-02,  3.7064e-02,  4.5018e-02,  3.9367e-01,\n",
      "        -1.3580e-01, -4.6021e-02,  2.3260e-01,  3.4156e-02,  8.4838e-02,\n",
      "         3.8056e-02, -3.4659e-03, -6.8177e-02,  8.2606e-02,  1.5811e-01,\n",
      "        -1.9388e-01,  6.1247e-02, -3.4282e-01, -2.3392e-01,  9.1131e-02,\n",
      "        -2.0934e+00,  1.3815e-01,  1.7597e-01, -3.8005e-01,  2.4690e-01,\n",
      "        -2.2482e-01, -5.9415e-02,  4.2415e-01, -1.3768e-01, -6.4184e-02,\n",
      "        -6.3230e-02,  1.0228e-01,  3.9662e-02, -2.8910e-01,  8.0242e-02,\n",
      "        -4.2854e-01,  1.0474e-01, -1.4070e-01, -5.0420e-02, -1.3486e-01,\n",
      "        -1.3077e-01, -1.1560e-01, -3.7648e-01,  1.4467e-02,  2.8400e-02,\n",
      "        -1.4921e-01,  2.9029e-01, -9.9163e-02,  2.2967e-01,  4.9717e-02,\n",
      "        -2.4345e-01,  2.7722e-02,  7.4055e-02, -4.2579e-01,  1.6724e-01,\n",
      "         6.5469e-02,  7.7571e-02,  2.1529e-01, -7.1330e-02, -5.2742e-02,\n",
      "         1.2080e-01, -5.6503e-02, -3.5852e-01, -8.5641e-02,  5.3364e-01,\n",
      "         1.8189e-01, -1.7887e-01, -2.0100e-01,  4.3655e-01,  1.7912e-01,\n",
      "         2.2238e-02, -4.8491e-02, -8.8347e-02, -1.7544e-01, -1.7052e-01,\n",
      "         2.7578e-01, -2.7629e-01, -5.6030e-02,  3.0416e-01,  4.5115e-01,\n",
      "         6.8440e-02, -1.5926e-01, -2.7197e-01, -2.2628e-02,  3.4567e-01,\n",
      "        -8.8622e-02,  1.9358e-01, -4.1653e-02,  4.1661e-01,  1.0848e-01,\n",
      "        -6.9752e-02, -2.3749e-01, -1.8511e-01,  8.8535e-03, -1.2773e-01,\n",
      "        -8.2802e-02,  4.5794e-02,  3.3554e-01, -3.0644e-01,  4.4171e-01,\n",
      "         1.5975e-01, -1.2756e-02, -2.6972e-01, -7.8977e-02, -4.8264e-02,\n",
      "        -6.5962e-02, -3.0006e-01,  1.0440e-01, -1.2715e-01, -1.4488e-02,\n",
      "        -3.5107e-01, -1.1407e-01,  6.6343e-01,  1.6589e-01,  1.5040e-02,\n",
      "        -8.3249e-03,  1.3835e-02, -1.9600e-01, -3.6130e-02,  2.0337e-01,\n",
      "         1.1822e-01,  1.4760e-01, -3.9074e-02,  2.4619e-01, -9.6280e-02,\n",
      "        -2.2719e-01, -2.2597e-01,  1.9236e-01, -4.1362e-01,  3.7821e-01,\n",
      "         2.8114e-01, -7.8232e-02, -2.4852e-01,  8.4978e-02,  4.5680e-01,\n",
      "         4.7818e-01, -7.2192e-02, -2.2441e-01, -2.5713e-01,  1.1820e-01,\n",
      "         1.8028e-01,  5.1181e-01,  4.0904e-01, -2.4304e-01,  4.9090e-01,\n",
      "        -3.9707e-01, -5.1963e-02,  1.7818e-02,  2.5160e-01,  2.8290e-01,\n",
      "         2.2776e-01, -2.5844e-01,  1.4281e-01, -7.2607e-02,  1.5194e-01,\n",
      "         2.5309e-01,  4.7232e-02,  2.5905e-01, -9.3313e-02,  1.1226e-01,\n",
      "        -1.7449e-01, -3.4896e-01, -2.0145e-01,  1.1628e-01, -1.0769e-01,\n",
      "        -7.8528e-02,  9.3096e-02, -1.6539e-01,  4.3994e-02,  5.9698e-02,\n",
      "        -1.3047e-01,  7.2147e-02,  3.3663e-03, -1.8181e-01,  3.1465e-02,\n",
      "        -3.5351e-02, -4.7912e-03,  9.2753e-02,  2.8618e-01,  1.3646e-01])\n",
      "torch.Size([300])\n"
     ]
    }
   ],
   "source": [
    "vectors=GloVe()\n",
    "vectors['hello']\n",
    "print(vectors['go'], vectors['pig'].shape, sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
